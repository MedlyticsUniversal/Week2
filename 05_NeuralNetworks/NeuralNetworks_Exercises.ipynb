{"cells":[{"cell_type":"markdown","metadata":{"id":"PlpG_fIiqdJU","colab_type":"text","cell_id":"1b1e7a8f8dca4a84943eca04322ec7be","deepnote_cell_type":"markdown"},"source":"# Neural Network Exercises\n\nIn these exercises, you will be building your own artificial neural network and seeing how adding different types of layers can affect the validation/testing accuracy. This is based off of the simple neural network with Keras tutorial, so you can reference that for further explanations as well.","block_group":"76541f7ddf454bc5bb43c00b93cf0aa2"},{"cell_type":"code","metadata":{"id":"eFSzOvSduDf8","colab":{},"colab_type":"code","source_hash":null,"execution_start":1697326070349,"execution_millis":1210,"deepnote_to_be_reexecuted":false,"cell_id":"9931f97ff5ee4874b304e4a15057e2ae","deepnote_cell_type":"code"},"source":"import os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport tensorflow as tf","block_group":"8c3fd672fbbd4b8c95fa9fe6828f67c7","execution_count":null,"outputs":[{"name":"stderr","text":"2023-10-14 23:27:50.819517: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-10-14 23:27:50.819621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-10-14 23:27:50.819628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"id":"Ep_09mlyqa5G","colab":{},"colab_type":"code","source_hash":null,"execution_start":1697326074857,"execution_millis":156,"deepnote_to_be_reexecuted":false,"cell_id":"02c95882cf4e488eb750abb39043ee32","deepnote_cell_type":"code"},"source":"os.system('wget https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Week2/spoken_digit_manual_features.csv')","block_group":"e908c1200c7d47f59c4ee65f54f01d59","execution_count":null,"outputs":[{"name":"stderr","text":"--2023-10-14 23:27:54--  https://raw.githubusercontent.com/MedlyticsUniversal/Data/main/Week2/spoken_digit_manual_features.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 220478 (215K) [text/plain]\nSaving to: ‘spoken_digit_manual_features.csv.1’\n\n     0K .......... .......... .......... .......... .......... 23% 52.4M 0s\n    50K .......... .......... .......... .......... .......... 46% 42.0M 0s\n   100K .......... .......... .......... .......... .......... 69% 52.3M 0s\n   150K .......... .......... .......... .......... .......... 92% 49.7M 0s\n   200K .......... .....                                      100%  470M=0.004s\n\n2023-10-14 23:27:54 (52.0 MB/s) - ‘spoken_digit_manual_features.csv.1’ saved [220478/220478]\n\n","output_type":"stream"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"zChcGaqVysRB","colab_type":"text","cell_id":"c99d701e64c0463d88d6af17d1ffe3b7","deepnote_cell_type":"markdown"},"source":"## Load Training Data and Pre-processed Features\n\nYour goal is to build a neural network that learns to classify which of the 5 speakers is recorded in a signal sample. Your prediction will be based off of features we've already pre-extracted for you and put into this CSV file: spectral centroid `SC`, spectral flatness `SF`, and maximum frequency `MF`.","block_group":"884e65e1694d464d900ef8ae196d5892"},{"cell_type":"code","metadata":{"id":"SVwsmOGvw7jp","colab":{"height":271,"base_uri":"https://localhost:8080/"},"outputId":"409b8bcb-249f-4f4e-f39b-c6747600a395","colab_type":"code","source_hash":null,"execution_start":1697326078266,"execution_millis":130,"deepnote_to_be_reexecuted":false,"cell_id":"814416e30e4b4099bd7d1527af693363","deepnote_cell_type":"code"},"source":"# Load csv containing raw data, labels, and pre-processed features\nspoken_df = pd.read_csv('spoken_digit_manual_features.csv', index_col = 0)\nprint(spoken_df.head(10))\nprint('\\n')\n\n# Set speakers\nspeakers = set(spoken_df['speaker'])\nprint(f'There are {len(speakers)} unique speakers in the dataset')","block_group":"ba16a0fe8bb54db0af3bce6fa2faba71","execution_count":null,"outputs":[{"name":"stdout","text":"                file  digit   speaker  trial           SC        SF  \\\n0   5_yweweler_8.wav      5  yweweler      8  1029.497959  0.397336   \n1    3_george_49.wav      3    george      4  1881.296834  0.387050   \n2  9_yweweler_44.wav      9  yweweler      4  1093.951856  0.394981   \n3  8_yweweler_33.wav      8  yweweler      3  1409.543285  0.487496   \n4      7_theo_34.wav      7      theo      3   887.361601  0.396825   \n5   1_jackson_45.wav      1   jackson      4  1007.568129  0.324100   \n6  6_yweweler_18.wav      6  yweweler      1  1286.701352  0.498813   \n7    9_george_35.wav      9    george      3  1405.092061  0.353083   \n8   9_jackson_32.wav      9   jackson      3  1172.899961  0.477907   \n9    8_george_26.wav      8    george      2  1959.977577  0.462901   \n\n           MF  \n0  745.878340  \n1  323.943662  \n2  244.648318  \n3  392.350401  \n4  130.640309  \n5  216.306156  \n6  400.715564  \n7  447.239693  \n8  114.892780  \n9  320.537966  \n\n\nThere are 5 unique speakers in the dataset\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"id":"nLRtFkiYAc3N","colab":{},"colab_type":"code","source_hash":null,"execution_start":1697326078655,"execution_millis":9,"deepnote_to_be_reexecuted":false,"cell_id":"f4243984fb1f4d3d8ba17b2387f85deb","deepnote_cell_type":"code"},"source":"# Make dictionary to convert from speaker names to indices\nname2int_dict = {name: ind for (ind, name) in enumerate(set(spoken_df['speaker']))}\n\ny_labels = spoken_df['speaker']\n# Set y_labels to be indices of speaker\ny_labels = [name2int_dict[name] for name in y_labels]","block_group":"d3ab0c4401454e7caf8ffeab0b2a2c9b","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xUhDZMw1A93D","colab_type":"text","cell_id":"b50a8dbb8f654469bbfa071daf40674a","deepnote_cell_type":"markdown"},"source":"Split data into train, validation, and test sets and standardize:","block_group":"8647e3bce8754816966843d45c38aa06"},{"cell_type":"code","metadata":{"id":"TAuzw6ibA3Es","colab":{},"colab_type":"code","source_hash":null,"execution_start":1697326081698,"execution_millis":13,"deepnote_to_be_reexecuted":false,"cell_id":"31bcbe2de15b43c199e6971e49a0798a","deepnote_cell_type":"code"},"source":"# Downselect to only the 3 columns of the dataset we are learning from, aka the features\nX_data = spoken_df[['SC', 'SF', 'MF']].to_numpy()\n\n# Decide how large to make validation and test sets\nn_val = 250\nn_test = 250\n\n# Shuffle data before partitioning\nX_data, y_labels = shuffle(X_data, y_labels, random_state = 25)\n\n# Partition\nX_data_test, y_labels_test = X_data[:n_test,:], y_labels[:n_test]\nX_data_val, y_labels_val = X_data[n_test:n_test+n_val,:], y_labels[n_test:n_test+n_val]\nX_data_train, y_labels_train = X_data[n_test+n_val:,:], y_labels[n_test+n_val:]\n\n# Scale data\nscaler = StandardScaler()\nX_data_train=scaler.fit_transform(X_data_train)\nX_data_val = scaler.transform(X_data_val)\nX_data_test = scaler.transform(X_data_test)","block_group":"28f608da40574abab4c5fb811c0e79ee","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mArY7lB4Akv1","colab_type":"text","cell_id":"1d4f37c59c0e4e2b825dda877c9807d6","deepnote_cell_type":"markdown"},"source":"Converting labels to \"one-hot\" vectors:","block_group":"637a380595d14cd2915a2bc8e83cf8fb"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697326085240,"execution_millis":103,"deepnote_to_be_reexecuted":false,"cell_id":"68c6ff2899fc41489d8caf45f813e97e","deepnote_cell_type":"code"},"source":"# Convert labels to onehot\ny_labels_train = tf.keras.utils.to_categorical(y_labels_train, 5)\ny_labels_val =  tf.keras.utils.to_categorical(y_labels_val, 5)\ny_labels_test =  tf.keras.utils.to_categorical(y_labels_test, 5)\n\ntraining_set = tf.data.Dataset.from_tensor_slices((X_data_train, y_labels_train))","block_group":"cfdb3eb0652d447f9e16669898caacfc","execution_count":null,"outputs":[{"name":"stderr","text":"2023-10-14 23:28:05.304527: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2023-10-14 23:28:05.304557: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2023-10-14 23:28:05.304573: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-c2703ed7-f8b4-40f5-8dd1-77fe823e4d60): /proc/driver/nvidia/version does not exist\n2023-10-14 23:28:05.304865: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"riycN8SdyxNT","colab_type":"text","cell_id":"0342111c321144febeb1fea210080058","deepnote_cell_type":"markdown"},"source":"## Additional Layers\n\nBefore you get to building your own neural network, we'll show you some examples of additional layers you can potetially add that we didn't go over in the tutorial. After reading over our explanations/example code and going through documentation, you'll be testing some of these out by putting together a neural network yourself.","block_group":"d3b44fcbba9e411aa87f2aa1efc81927"},{"cell_type":"markdown","metadata":{"id":"DoaZsqc3iEyv","colab_type":"text","cell_id":"758753d2d62e4ea7afc193a00d79f08d","deepnote_cell_type":"markdown"},"source":"### Dropout Layers\n\nDropout layers randomly omit, or drop, some elements of the output vector from the layer, which helps prevent overfitting and can improve the generalization of your neural network. The dropout rate can be any number between 0 and 1.\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n\n```\n# Example\nd_r = 0.6\ntf.keras.layers.Dropout(rate=d_r)\n```","block_group":"24495a5b3ccb4f1985203e3312322768"},{"cell_type":"markdown","metadata":{"id":"gVJMrZ09iUgk","colab_type":"text","cell_id":"542c597c386247a99d854d8b6c3c7d61","deepnote_cell_type":"markdown"},"source":"### Pooling Layers\n\nA pooling layer reduces dimensionality (the size of each feature map) and \"compresses\" information by combining several output elements. Two common functions used for pooling are:\n- **Average pooling**: calculating the average value for each patch on the feature map\n- **Max pooling**: calculating the maximum value for each patch of the feature map\n\n*Note: we won't apply pooling in this exercise notebook, but you'll be seeing more of it in future ones*\n\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool1D\n\n```\n# Example\ntf.keras.layers.MaxPool1D(pool_size=1)\n```","block_group":"e9e84218553e4ffaafba4dedfb709709"},{"cell_type":"markdown","metadata":{"id":"72ngF_beiaV9","colab_type":"text","cell_id":"190a0a263a024786a3dd55ed078e9d50","deepnote_cell_type":"markdown"},"source":"### Activation Layers/Functions\n\nAn activation function looks at each \"neuron\" in your neural network and determines whether it should be activated (fired) or not, based on the relevancy of the neuron's input to the model's predictions. Some different activation functions you could look at are:\n- **Softmax**: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax\n- **Sigmoid**: https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid\n- **Softplus**: https://www.tensorflow.org/api_docs/python/tf/keras/activations/softplus\n- **ReLU**: https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU\n\n```\n# Example\ntf.keras.layers.Softmax()\n```","block_group":"4312d1b818e64ca3b691736be29b7056"},{"cell_type":"markdown","metadata":{"id":"zCdxM6HDqR1F","colab_type":"text","cell_id":"0dc77688a94c44639f62cec6da121efe","deepnote_cell_type":"markdown"},"source":"### Optimization Functions\n\n- **Adam**: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n    - Adam is computationally efficient, has little memory requirement, and is well suited for problems that are large in terms of data/parameter.\n- **Adagrad**: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad\n    - Adagrad is an optimizer that is best used for sparse data. Some of its benefits are that it converges more quickly and doesn't need manual adjustment of the hyperparameter \"learning rate\".\n- **SGD**: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD\n    - SGD is a **stochastic gradient descent** and momentum optimizer. SGD essentially helps gradient vectors move down loss functions towards the minimum point, leading to faster \"converging.\"\n- **RMSprop**: https://keras.io/api/optimizers/rmsprop/\n    - As you may already know, the learning rate regulates how much the model can change based on the estimated error (which occurs every time the model's weights are updated). Instead of treating the learning rate as a hyperparamter, RMSprop is an optimization technique that relies on a changing, adaptive learning rate.\n\n```\n# Example code\nl_r = .001 \ntf.keras.optimizers.SGD(learning_rate=l_r)\n```","block_group":"96e9c93d1eb34ca19aa3491e1b23da42"},{"cell_type":"markdown","metadata":{"id":"ldbularZ3cCW","colab_type":"text","cell_id":"4e56c12653524ad7bb210ea3a8d25b61","deepnote_cell_type":"markdown"},"source":"## Putting Together Your Neural Network\n\nNow you will experiment with adding different layers to your neural network. We've added some guiding comments to give you a place to start and test out, but we also strongly encourage you to go through all the documentation and use the Internet as well!","block_group":"97f2b4a60e614018ad2783d55e49a091"},{"cell_type":"code","metadata":{"id":"qMp_z7W9vZV4","colab":{},"colab_type":"code","source_hash":null,"execution_start":1697326089930,"execution_millis":40,"deepnote_to_be_reexecuted":false,"cell_id":"23ad53ee5f914916a3f0520aa874b4a9","deepnote_cell_type":"code"},"source":"# Once you've gone through all the tests, play around with these rates to see if you can increase your accuracy.\nl_r = .001\nd_r = 0.6\n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(8, input_shape=(3,)))","block_group":"8f35b10d8ce24ba4b17c97c14847f101","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8OQKRfNjBWGC","colab_type":"text","cell_id":"fad96bef5bd946c39aad4ae19d1c2eab","deepnote_cell_type":"markdown"},"source":"### Test 1","block_group":"19a77476f0d4460584b07bdd1e8c346b"},{"cell_type":"code","metadata":{"id":"BneaEDk-BWj2","colab":{},"colab_type":"code","source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"5596821c486146ee977fcf21b064b53f","deepnote_cell_type":"code"},"source":"# Run this cell as it is\nmodel.add(tf.keras.layers.Dense(8))\nmodel.add(tf.keras.layers.Dense(8))\n\n# Output dimension needs to be number of classes in order for each to get a score\nmodel.add(tf.keras.layers.Dense(5))\n\n# NOW SKIP down to the section that compiles and trains your model and run those cells.\n# Check the pseudo-test accuracy and see how well the bare minimum performed.","block_group":"691b6bb39eef412ca07269d89441aca2","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"djwaQho7_xBt","colab_type":"text","cell_id":"81c10ad7015e4004a7072aceb02aba5c","deepnote_cell_type":"markdown"},"source":"### Test 2","block_group":"845710207e184b589464e1a5b042be8d"},{"cell_type":"code","metadata":{"id":"o2MQzNEa_ViW","colab":{},"colab_type":"code","source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"fbdcd1d1741a477ca41497f7f3548d7f","deepnote_cell_type":"code"},"source":"# ADD activation layer here\nmodel.add(tf.keras.layers.Dense(8))\n# ADD activation layer here\nmodel.add(tf.keras.layers.Dense(8))\n# ADD activation layer here\n\n# Output dimension needs to be number of classes in order for each to get a score\nmodel.add(tf.keras.layers.Dense(5))\n\n# NOW SKIP down to the section that compiles and trains your model and re-run those cells.\n# What do you notice about the testing/validation accuracy after test 2 in comparison to test 1?","block_group":"798428ec398845788dbbf5a702f62330","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M_pr4L_0Bzt_","colab_type":"text","cell_id":"dff59131789841a9808d7f3084c31702","deepnote_cell_type":"markdown"},"source":"### Test 3","block_group":"a944ed333e594013a49e5f8fa585d4bc"},{"cell_type":"code","metadata":{"id":"pb-7sVYkB11c","colab":{},"colab_type":"code","source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"0d46a3a818a34bf5953b9e406c8c9537","deepnote_cell_type":"code"},"source":"# ADD activation layer here\nmodel.add(tf.keras.layers.Dense(8))\n# ADD activation layer here\nmodel.add(tf.keras.layers.Dense(8))\n# ADD activation layer here \n\n# Output dimension needs to be number of classes in order for each to get a score\nmodel.add(tf.keras.layers.Dense(5))\n\n# ADD dropout layer here\n\n# Now skip down to the section that compiles and trains your model and re-run those cells.\n# What do you notice about the testing/validation accuracy after test 3 in comparison to tests 1 & 2?","block_group":"fc1605793e71410da653ef8ebc2f1d6c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YwjD-MgMDHFV","colab_type":"text","cell_id":"5f86a0e2a12347beb0f01f7d6c369e00","deepnote_cell_type":"markdown"},"source":"### Test 4\n\nNow go back down to the cell where you compiled your model and this time, change the optimizer. It's been set to `Adam` as default but as we showed you above, there are other functions that you can test out.","block_group":"afebd7b991fb43ba875ce33cd72d33f4"},{"cell_type":"markdown","metadata":{"id":"Qhna7lr5Dm56","colab_type":"text","cell_id":"07bd7fbda967497995bed1f3b5b9d2f2","deepnote_cell_type":"markdown"},"source":"## Compiling and Training Your Model","block_group":"6c86eece4e1444858cdbaf5631cb5df6"},{"cell_type":"code","metadata":{"cell_id":"36e93298d30b41d28e427019a4e6ae87","deepnote_cell_type":"code"},"source":"model.summary()","block_group":"c6a0b66560fa480f9786edc7db4a59d2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XB1qNpsoASGv","colab":{},"colab_type":"code","source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"1950e2e80c5f4caab9f288def176944e","deepnote_cell_type":"code"},"source":"model.compile(loss = tf.keras.losses.categorical_crossentropy, \n              optimizer = tf.keras.optimizers.Adam(learning_rate=l_r),\n              metrics = ['accuracy'])   ","block_group":"d1960d748b3b42f9bdd369505cf805bc","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tj1lwAY7BJPk","colab_type":"text","cell_id":"7b2151c72c484aeb86f294df286fd780","deepnote_cell_type":"markdown"},"source":"Specify number of epochs and batch size, and fit the model to data:","block_group":"9ff060e2d7744f2dbbf36d922ecdff54"},{"cell_type":"code","metadata":{"id":"uF2RT0eGBIlD","colab":{},"colab_type":"code","source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"0d90a1e543914c898edfc80ebe4bead6","deepnote_cell_type":"code"},"source":"EPOCHS = 50\nbatch_size = 100\n\ntraining_set = training_set.batch(batch_size) # Set batch size\n\nfor epoch in range(EPOCHS):\n    for signals, labels in training_set:\n        tr_loss, tr_accuracy = model.train_on_batch(signals, labels)\n    val_loss, val_accuracy = model.evaluate(X_data_val, y_labels_val)\n    print(('Epoch #%d\\t Training Loss: %.2f\\tTraining Accuracy: %.2f\\t'\n         'Validation Loss: %.2f\\tValidation Accuracy: %.2f')\n         % (epoch + 1, tr_loss, tr_accuracy,\n         val_loss, val_accuracy))","block_group":"de509ec830944b27856dc1844b40fc90","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GipGyEkBQdj","colab":{},"colab_type":"code","source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"38782cbd710c44fe9b6b0ae33368db65","deepnote_cell_type":"code"},"source":"# Check performance on test set\ntest_loss, test_accuracy = model.evaluate(X_data_test, y_labels_test)","block_group":"8c83fc0799bb4316a49abad6593481ae","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"maTNvEQpbkoS","colab_type":"text","cell_id":"ccda3d7b5c5e463696d0e192a006cde0","deepnote_cell_type":"markdown"},"source":"Now create your own model and/or modify the existing model, and try to find the highest, appropriate testing and validation accuracies!","block_group":"29033c169afa4ba5b7f9fdc57efed96f"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c2703ed7-f8b4-40f5-8dd1-77fe823e4d60' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NeuralNetworks_Exercises.ipynb","provenance":[],"collapsed_sections":[]},"deepnote":{},"kernelspec":{"name":"python3","display_name":"Python 3"},"deepnote_notebook_id":"feaa87b0ca264423ba0937d648c2af2a","deepnote_execution_queue":[]}}